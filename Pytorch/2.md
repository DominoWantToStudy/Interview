### 11.nn.Softmax
softmax激活函数，参数dim=0表示每一列和为1，dim=1表示每一行和为1
```Python
nn.Softmax(dim=1)
```
### 12.nn.CrossEntropyLoss
nn.CrossEntropyLoss(y,lable)为交叉熵损失函数，用于解决多分类问题，也可解决二分类问题。在使用nn.CrossEntropyLoss()其内部会自动加上Sofrmax层，函数的两个参数分别为：  
__y__：参数y为输入也是网络的最后一层的输出，其shape为[batchsize,class num]（函数要求第一个参数为二维数据，每个向量中的值为不同种类的概率值），如果batchsize大于1，那么求对应的均值  
__label__：传入的标签，也就是某个类别的索引值
### 13.torch.optim
搭建网络之后需要用优化器来求解优化问题，可使用torch.optim包构造优化器对象，并指定优化参数如学习率，权重衰减率等
```Python
optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)
optimizer = optim.Adam(model.parameters(), lr = 0.0001)
#结合损失函数可以写出训练流程
model = model_CNN_1()
criterion = nn.CrossEntropyLoss()
...
inputs,labels = data
predictions = model(inputs)
loss = criterion(predictions,labels)   #loss = criterion(predictions,labels.long())
optimizer.zero_grad()
loss.backward()
optimizer.step()
```
